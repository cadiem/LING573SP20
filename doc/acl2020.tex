\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2020}
\usepackage{times}
\usepackage{tabularx}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{subfig}
\renewcommand{\UrlFont}{\ttfamily\small}
\newcommand{\spacemanidol}[1]{\textcolor{orange}{\bf \small [#1 --dc]}}
\setlength\titlebox{5cm}
\newcommand\BibTeX{B\textsc{ib}\TeX}
\usepackage{microtype}
\aclfinalcopy 
\title{LING 573:Document Summarization Project Report}
\author{Daniel Campos, Sicong Huang, Shunjie Wang, Simola Nayak, \and Hayley Luke \\ University of Washington \\ {\tt\{dacamp, huangs33, shunjiew, simnayak, jhluke\}@uw.edu}}
\begin{document}
\maketitle
\begin{abstract}
We design and implement Mockingbird, a topic-focused multi-document extractive summarization system. Building on the LexRank graph algorithm our system uses sentence similarity and topic-sentence bias to produce candidates. Next, the ranked sentences are  selected to limit redundancy and stay under 100 words. Compare to the LEAD baseline this system *******. Future work will focus on forms of text representation and processing along with more complex selection and sorting can improve system performance
\end{abstract}
\section{Introduction}
Topic oriented document clusters like ACQUAINT \cite{Graff2002TheAC} and ACQUAINT-2 have been used as a starting point to explore various methods for document summarization. More specifically, these corpuses have been used to study extractive multi-document topic summarization. These corpuses have been the focus of study in TAC(Text Analytics Conference) \cite{} summarization shared task. In the formalization of this task give a topic and a set of news wire documents a competitive system should create a high quality summary of the topic using sentences from the documents. Systems are expected to produce summaries up to 100 words and summaries should be coherent and not contain duplication. Once summaries are generated for all the topics being studied, methods are evaluated and compared using the standard ROUGE metric \cite{}.  \\ Our exploratory system, called Mockingbird, is based on the Biased LexRank graph approach \cite{Otterbacher2009BiasedLP}. In this approach, we provide a ranking of all candidate sentences by combining a matrix which represents sentence similarity with a topic and sentence similarity. After a ranking is produced sentences are selected to maximize their lexrank score but minimize duplication of content. Our method relies on word vectors \cite{Mikolov2013DistributedRO} from the spacy library \footnote{https://spacy.io/} to represent sentences and we experiment with the effects of evaluating complete sentences, sentences without stop words, and only the nouns in the sentences. To understand our system performance we compare our systems ROUGE-1 and ROUGE-2 scores when compared to LEAD, and MEAD baselines. Our system across the board performs \spacemanidol{TODO add basic summary of results}. 
\section{System Overview}
Mockingbird has been designed as a simple end-to-end pipeline with the goal of producing a structure we can continue to tweak and modify to understand the effect of various changes have on downstream performance. The pipeline broadly has 5 steps: document input and processing, content selection, information ordering, content realization, and evaluation.\\
\spacemanidol{This is where we add a figure 1 for system architecture}
\section{Approach}
In this section we will describe the in detail each of the steps our system takes to summarize topics.
\subsection{Data Input and Processing}
The document pipeline takes as an input a configuration file which contains \spacemanidol{what happens}. Using this configuration we  \spacemanidol{@Hayley is this a correct approximation of your code?}.\\
\subsection{Content Selection}
Next, there is the content selection pipeline. In this step we consume the structured information from the processing pipeline and for each topic we first assemble all sentences in scope of the topic that have at least 5 words. Then for each sentence, and the title we compute a vector representation for each sentence by averaging all the word vectors in a sentence. We implement various methods of text normalization to focus on the true meaning of the sentence. Once sentences are processed we generate a two dimension matrix representing the cosine similarity between all the sentences relevant to the topic. Following this we produce a bias vector which contains the cosine distance between each sentence and the topic. 
\subsection{Information Ordering}
Following content selection we run our information ordering system. \spacemanidol{Shunjie describe what you do}.\\
\subsection{Content Realization}
\spacemanidol{I suspect for V1 we will just take the information ordering stuff and output}
\section{Results}
To evaluate our system performance we ran our system on the 2010 TAC shared evaluation task. 
The total number of systems this year was 43 including two baselines. The 1st baseline
(LEAD) was the first 100 words from the most recent document, the 2nd baseline was the
output of the MEAD summarize (Radev et al., 2003). 23 groups participated.
\section{Discussion}
This is our discussion
\section{Conclusion and Future Work}
We find our model BLAGH
We want to do Blagh
\bibliography{acl2020}
\bibliographystyle{acl_natbib}
\end{document}